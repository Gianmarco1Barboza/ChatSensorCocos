import os
import json
import time
import random
import numpy as np
from coppeliasim_zmqremoteapi_client import RemoteAPIClient

# =========================================================
# -------- CONFIG QUE *TÚ* PUEDES / DEBES TOCAR ----------
# =========================================================

WHEEL_D = 0.05          # m (diámetro de la llanta)
MAX_SPEED = 1.2         # m/s máx que quieres permitir
MAX_CORRECTION = 0.6    # límite del giro diferencial (más alto = gira más brusco)

# MUY IMPORTANTE:
# Tus sensores están montados físicamente del lado IZQUIERDO del robot,
# pero en el código parecían como si estuvieran a la DERECHA.
#
# Para corregir eso, usamos pesos "invertidos":
# - Si un sensor con índice bajo detecta la línea, eso debe contarse
#   como "línea está muy a mi IZQUIERDA" (error NEGATIVO grande).
# - Si un sensor con índice alto detecta línea, eso es más "a mi DERECHA"
#   (error POSITIVO).
#
# Esta versión ya invierte esa lógica para que el error salga con el
# signo correcto cuando la línea está bajo tu arreglo a la izquierda.
WEIGHTS = np.array([3, 2, 1, 0.5, -0.5, -1, -2, -3], dtype=float)
# OJO: antes teníamos [-3, -2, ... , 3].
# Ahora lo volteamos porque físicamente tus sensores están
# desplazados a la izquierda pero el código pensaba en espejo.

# STEERING_SIGN: si AÚN así el robot gira al lado contrario,
# cambia esto de 1.0 a -1.0.
STEERING_SIGN = 1.0

# Tiempo que dura cada episodio de entrenamiento (segundos reales)
EPISODE_TIME = 4.0

# Tiempo entre pasos de control
CONTROL_DT = 0.02

# Si ningún sensor ve la línea (todos 0), asumimos "línea perdida"
LOST_LINE_THRESHOLD = 0

# Carpeta para guardar resultados
LOG_DIR = "logs"
os.makedirs(LOG_DIR, exist_ok=True)


# =========================================================
# --------- CONEXIÓN A COPPELIASIM Y HANDLES --------------
# =========================================================

client = RemoteAPIClient('localhost', 23000)
sim = client.getObject('sim')

left_mtr = sim.getObject('/LineTracer/DynamicLeftJoint')
right_mtr = sim.getObject('/LineTracer/DynamicRightJoint')
cam_handles = [sim.getObject(f"/LineTracer/lineSensor[{i}]") for i in range(8)]


# =========================================================
# ---------------- FUNCIONES DEL ROBOT --------------------
# =========================================================

def get_sensor_values(threshold=0.2):
    """
    Lee los 8 sensores de visión y regresa una lista tipo [0,1,1,0,0,0,0,0]
    1 = línea negra detectada.
    """
    states = []
    for h in cam_handles:
        img, res = sim.getVisionSensorImg(h)
        w, hres = int(res[0]), int(res[1])

        buf = np.frombuffer(img, dtype=np.uint8)
        frame = buf.reshape(hres, w, 3).astype(np.float32) / 255.0
        gray = frame.mean(axis=2)

        detected = 1 if gray.mean() < threshold else 0
        states.append(detected)
    return states


def set_motor_speeds(norm_left, norm_right):
    """
    norm_left / norm_right en [-1,1].
    Pasamos eso a velocidad angular de cada llanta y lo mandamos al sim.
    """
    # saturamos a [-1,1]
    nl = max(-1.0, min(1.0, norm_left))
    nr = max(-1.0, min(1.0, norm_right))

    # normalizado -> velocidad lineal (m/s)
    left_linear_velocity = nl * MAX_SPEED
    right_linear_velocity = nr * MAX_SPEED

    # lineal -> angular [rad/s]
    left_ang_vel = left_linear_velocity / (WHEEL_D / 2)
    right_ang_vel = right_linear_velocity / (WHEEL_D / 2)

    client.setStepping(True)
    sim.setJointTargetVelocity(left_mtr, left_ang_vel)
    sim.setJointTargetVelocity(right_mtr, right_ang_vel)
    client.setStepping(False)

    return nl, nr  # regresamos lo que mandamos por si lo queremos medir


def compute_line_error(sensors, last_error):
    """
    Convierte las lecturas binarias de los sensores en un error continuo.
    Con los WEIGHTS ya volteados para que la línea que está "a tu izquierda física"
    se represente como error negativo.
    """
    s = np.array(sensors, dtype=float)
    active_sum = s.sum()

    if active_sum <= LOST_LINE_THRESHOLD:
        # línea perdida -> sigue girando en la misma dirección previa
        return last_error

    weighted_pos = (WEIGHTS * s).sum() / active_sum
    return weighted_pos


class PIDController:
    """
    Control PID clásico: salida = Kp*e + Ki*∫e dt + Kd*de/dt
    """
    def __init__(self, Kp, Ki, Kd):
        self.Kp = Kp
        self.Ki = Ki
        self.Kd = Kd
        self.integral = 0.0
        self.prev_error = 0.0
        self.prev_time = None

    def reset(self):
        self.integral = 0.0
        self.prev_error = 0.0
        self.prev_time = None

    def update(self, error):
        now = time.time()
        if self.prev_time is None:
            dt = 0.0
        else:
            dt = now - self.prev_time
            if dt <= 0:
                dt = 1e-6

        # PID
        P = self.Kp * error
        self.integral += error * dt
        I = self.Ki * self.integral
        d_error = (error - self.prev_error) / dt if dt > 0 else 0.0
        D = self.Kd * d_error

        # memoria para siguiente llamada
        self.prev_error = error
        self.prev_time = now

        return P + I + D


def apply_controller(pid_output, base_speed):
    """
    Traduce la salida del PID en velocidades de rueda.
    STEERING_SIGN arregla el sentido final del giro.
    """
    correction = STEERING_SIGN * pid_output

    # limitar giro máximo
    correction = max(-MAX_CORRECTION, min(MAX_CORRECTION, correction))

    left_cmd = base_speed - correction
    right_cmd = base_speed + correction

    # saturar para motores
    left_cmd = max(-1.0, min(1.0, left_cmd))
    right_cmd = max(-1.0, min(1.0, right_cmd))

    return set_motor_speeds(left_cmd, right_cmd)


# =========================================================
# ----------- EPISODIO DE ENTRENAMIENTO (ROLLOUT) ---------
# =========================================================

def run_episode(params, episode_idx):
    """
    Corre un episodio de simulación con:
      params = {
        "Kp": float,
        "Ki": float,
        "Kd": float,
        "BASE_SPEED": float
      }

    Calcula recompensa:
      - Quiere bajo error promedio (robot cerca de la línea)
      - Quiere avanzar hacia adelante (no quedarse girando en el lugar)

    Guarda resultados en logs/prueba_#.json
    Regresa (reward, data_dict)
    """

    pid = PIDController(params["Kp"], params["Ki"], params["Kd"])
    pid.reset()

    base_speed = params["BASE_SPEED"]

    # Reinicia la escena al estado inicial
    sim.stopSimulation()
    time.sleep(0.2)
    sim.startSimulation()

    start_time = time.time()
    last_error = 0.0

    abs_error_sum = 0.0    # qué tan lejos de la línea estuviste
    forward_sum = 0.0      # cuánto avanzaste hacia adelante
    step_count = 0

    while sim.getSimulationState() != sim.simulation_stopped:
        now = time.time()
        if (now - start_time) >= EPISODE_TIME:
            break

        sensors = get_sensor_values()
        err = compute_line_error(sensors, last_error)
        last_error = err

        pid_out = pid.update(err)

        left_cmd, right_cmd = apply_controller(pid_out, base_speed)

        # Métricas para reward
        abs_error_sum += abs(err)

        # "avance promedio": si ambas ruedas van hacia adelante, cuenta
        forward_cmd = (left_cmd + right_cmd) / 2.0
        if forward_cmd < 0:
            forward_cmd = 0.0
        forward_sum += forward_cmd

        step_count += 1

        time.sleep(CONTROL_DT)

    # paro robot y sim
    set_motor_speeds(0.0, 0.0)
    sim.stopSimulation()
    time.sleep(0.1)

    if step_count == 0:
        avg_err = 999.0
        avg_forward = 0.0
    else:
        avg_err = abs_error_sum / step_count
        avg_forward = forward_sum / step_count

    # Reward = queremos ir derecho (avg_forward alto) y pegados a la línea (avg_err bajo)
    reward = (2.0 * avg_forward) - (1.0 * avg_err)

    data = {
        "episode": episode_idx,
        "params": params,
        "avg_error": avg_err,
        "avg_forward": avg_forward,
        "reward": reward,
        "timestamp": time.time()
    }

    log_path = os.path.join(LOG_DIR, f"prueba_{episode_idx}.json")
    with open(log_path, "w") as f:
        json.dump(data, f, indent=2)

    print(f"[EP {episode_idx}] reward={reward:.3f}  err={avg_err:.3f}  fwd={avg_forward:.3f}")
    print(f"Guardado en {log_path}")

    return reward, data


# =========================================================
# ----------- BÚSQUEDA TIPO RL / EVOLUTIVA ----------------
# =========================================================

def mutate_params(best_params, scale=0.3):
    """
    Genera nuevos parámetros parecidos a los mejores hasta ahora,
    agregando un poco de ruido gaussiano.
    """
    def mutate_positive(val, allow_zero=True):
        new_val = val + random.gauss(0, scale * (abs(val) + 1e-6))
        if allow_zero:
            new_val = max(0.0, new_val)
        else:
            new_val = max(0.05, new_val)  # evitar 0 total en BASE_SPEED
        return new_val

    new_params = {
        "Kp": mutate_positive(best_params["Kp"]),
        "Ki": mutate_positive(best_params["Ki"]),
        "Kd": mutate_positive(best_params["Kd"]),
        "BASE_SPEED": mutate_positive(best_params["BASE_SPEED"], allow_zero=False),
    }

    # BASE_SPEED lo recortamos al rango [0,1] porque nuestro control asume eso
    new_params["BASE_SPEED"] = min(1.0, new_params["BASE_SPEED"])

    return new_params


def save_best(best_data):
    best_path = os.path.join(LOG_DIR, "best_params.json")
    with open(best_path, "w") as f:
        json.dump(best_data, f, indent=2)
    print(f"[MEJOR ACTUALIZADO] {best_path}")


if __name__ == "__main__":
    # Semilla inicial (puedes cambiarlos si quieres que empiece más lento/suave)
    best_params = {
        "Kp": 0.6,
        "Ki": 0.0,
        "Kd": 0.1,
        "BASE_SPEED": 0.4
    }

    # Episodio 0 con los iniciales
    best_reward, best_data = run_episode(best_params, episode_idx=0)
    save_best(best_data)

    # Cuántos episodios quieres probar en este run
    NUM_EPISODES = 10

    for ep in range(1, NUM_EPISODES + 1):
        cand_params = mutate_params(best_params, scale=0.3)

        reward, data = run_episode(cand_params, episode_idx=ep)

        # Si el candidato es mejor, lo adoptamos
        if reward > best_reward:
            best_reward = reward
            best_params = cand_params
            best_data = data
            save_best(best_data)

    # al final, motores en stop por seguridad
    set_motor_speeds(0.0, 0.0)
