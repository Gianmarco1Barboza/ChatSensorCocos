import time
import numpy as np
from coppeliasim_zmqremoteapi_client import RemoteAPIClient

# Usa los mismos pesos que reflejan tu arreglo de sensores en el lado izquierdo
WEIGHTS = np.array([3, 2, 1, 0.5, -0.5, -1, -2, -3], dtype=float)

client = RemoteAPIClient('localhost', 23000)
sim = client.getObject('sim')

left_mtr = sim.getObject('/LineTracer/DynamicLeftJoint')
right_mtr = sim.getObject('/LineTracer/DynamicRightJoint')
cam_handles = [sim.getObject(f"/LineTracer/lineSensor[{i}]") for i in range(8)]

def get_sensor_values(threshold=0.2):
    states = []
    for h in cam_handles:
        img, res = sim.getVisionSensorImg(h)
        w, hres = int(res[0]), int(res[1])
        buf = np.frombuffer(img, dtype=np.uint8)
        frame = buf.reshape(hres, w, 3).astype(np.float32) / 255.0
        gray = frame.mean(axis=2)
        detected = 1 if gray.mean() < threshold else 0
        states.append(detected)
    return states

def compute_weighted_pos(sensors):
    s = np.array(sensors, dtype=float)
    if s.sum() == 0:
        return None
    return float((WEIGHTS * s).sum() / s.sum())

def stop_motors():
    sim.setJointTargetVelocity(left_mtr, 0.0)
    sim.setJointTargetVelocity(right_mtr, 0.0)

if __name__ == "__main__":
    try:
        sim.startSimulation()
        time.sleep(0.2)

        print("Coloca el robot en la posición CORRECTA respecto a la línea, sin moverlo.")
        for _ in range(50):
            sensors = get_sensor_values()
            wpos = compute_weighted_pos(sensors)
            print("sensores =", sensors, "weighted_pos =", wpos)
            stop_motors()
            time.sleep(0.1)

    finally:
        sim.stopSimulation()
        stop_motors()
        print("Listo.")
